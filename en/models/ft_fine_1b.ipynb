{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485fc7f-46ec-466c-9e5d-fd29666479b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "import numpy as np\n",
    "from transformers import TFAutoModel\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate, MaxPool1D\n",
    "from tensorflow.keras.layers import GRU, LSTM,Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import warnings\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "np.random.seed(21)\n",
    "warnings.filterwarnings('ignore')\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5f4d0-6979-417c-9974-1eb6b6e1bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "model_name = 'vinai/bertweet-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)\n",
    "MAX_LEN = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d4a6a-8451-4b05-ac0c-63d6538ea593",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =pd.read_csv(\"../data/ext_data/task1b/train_full.csv\")\n",
    "test=pd.read_csv(\"../data/ext_data/task1b/test.csv\")\n",
    "FEATURES=[\"dale_chall\",\"bad_words\", \"num_words\",\"all_caps\",\t\"emoji\"\t,\"capitals\",\"total_length\",\"caps_vs_length\",\"num_unique_words\",\t\"words_vs_unique\"\t,\"num_urls\",\t\"!\",\t\"?\"]\n",
    "features = train[FEATURES].fillna(0)\n",
    "test_features = test[FEATURES].fillna(0)\n",
    "ss = StandardScaler()\n",
    "ss.fit(np.vstack((features, test_features)))\n",
    "features = ss.transform(features)\n",
    "test_features = ss.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c4faa-0209-4e32-b3e5-66337739be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for cutting off the middle part of long texts.\n",
    "def text_process(text):\n",
    "    ws = text.split(' ')\n",
    "    if(len(ws)>130):\n",
    "        text = ' '.join(ws[:90]) + ' ' + ' '.join(ws[-40:])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede8e6d-6cdf-4a83-9e92-64c9a08f142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[[\"NONE\",\"OFFN\",\"PRFN\"]].values\n",
    "y_test= test[[\"NONE\",\"OFFN\",\"PRFN\"]].values\n",
    "X_train = train['c_text'].apply(lambda x: text_process(str(x))).fillna(\"something\").values.tolist()\n",
    "X_test = test['c_text'].apply(lambda x: text_process(str(x))).fillna(\"something\").values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f733d7b-f7ca-4de7-bb2d-3efa16604b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(sentences, tokenizer, max_seq_len = 125 ):\n",
    "    tokenized_sentences = []\n",
    "\n",
    "    for sentence in tqdm(sentences):\n",
    "        tokenized_sentence = tokenizer.encode(\n",
    "                            sentence,\n",
    "                            truncation=True,               \n",
    "                            add_special_tokens = True, \n",
    "                            max_length = max_seq_len,\n",
    "                    )\n",
    "        \n",
    "        tokenized_sentences.append(tokenized_sentence)\n",
    "\n",
    "    return np.array(tokenized_sentences)\n",
    "\n",
    "def create_attention_masks(tokenized_and_padded_sentences):\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in tokenized_and_padded_sentences:\n",
    "        att_mask = [int(token_id > 0) for token_id in sentence]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return np.asarray(attention_masks)\n",
    "def regular_encode(texts,tokenizer,maxlen=MAX_LEN):\n",
    "  input_ids = tokenize_sentences(texts, tokenizer, MAX_LEN)\n",
    "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "  attention_masks = create_attention_masks(input_ids)\n",
    "  return input_ids,attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d692643e-6ab1-4b8b-a4bb-166609ce5058",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,x_test_att = regular_encode(X_test, tokenizer, maxlen=MAX_LEN)\n",
    "x_train,x_train_att = regular_encode(X_train,tokenizer,maxlen=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22374571-8f1c-4f13-8499-2b4b5e46974a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.max_score = 0\n",
    "        self.not_better_count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=1)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            if (score > self.max_score):\n",
    "                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n",
    "                model.save_weights(\"../checkpoints/ft_fine_1b.h5\")\n",
    "                self.max_score=score\n",
    "                self.not_better_count = 0\n",
    "            else:\n",
    "                self.not_better_count += 1\n",
    "                if self.not_better_count > 2:\n",
    "                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n",
    "                    self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88695c0-6e7a-43bb-ae9f-e32d9cd4cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(bert_model, features ,clipvalue=1.,num_filters=40,dropout=0.5,max_len=125):\n",
    "    import tensorflow as tf\n",
    "    features_input = Input(shape=(features.shape[1],))\n",
    "    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    attention_masks = Input(shape=(max_len,), dtype=tf.int32, name=\"input_att_masks\")\n",
    "    bert_output = bert_model(input_ids, attention_mask=attention_masks)\n",
    "    cls_token = bert_output.pooler_output\n",
    "    cls_token = Dense(50, activation=\"relu\")(cls_token)\n",
    "    cls_token = Dropout(0.5)(cls_token)\n",
    "    x = concatenate([cls_token,features_input])\n",
    "    outp = Dense(3, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=[input_ids,attention_masks,features_input], outputs=outp)\n",
    "    import tensorflow as tf\n",
    "    adam = tf.optimizers.Adam(clipvalue=clipvalue)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8223f0e-e6bb-4ef3-87ac-a966d9eb0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_layer = TFAutoModel.from_pretrained(model_name,output_hidden_states=True)\n",
    "transformer_layer.compile()\n",
    "model = get_model(transformer_layer, features)\n",
    "model.summary()\n",
    "epochs = 100\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "num_folds = 10\n",
    "predict = np.zeros((test.shape[0],3))\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
    "x_train=np.asarray(x_train).astype(np.float32)\n",
    "x_test=np.asarray(x_test).astype(np.float32)\n",
    "i=0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    i+=1\n",
    "    print(f\"fold: {i}\")\n",
    "    kfold_y_train,kfold_y_test = y_train[train_index], y_train[test_index]\n",
    "    kfold_X_train = x_train[train_index]\n",
    "    kfold_X_train_att = x_train_att[train_index]\n",
    "    kfold_X_features = features[train_index]\n",
    "    kfold_X_valid = x_train[test_index]\n",
    "    kfold_X_valid_att = x_train_att[test_index]\n",
    "    kfold_X_valid_features = features[test_index] \n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    model = get_model(transformer_layer, features)\n",
    "    ra_val = RocAucEvaluation(validation_data=([kfold_X_valid,kfold_X_valid_att,kfold_X_valid_features], kfold_y_test), interval = 1)\n",
    "    model.fit([kfold_X_train,kfold_X_train_att,kfold_X_features], kfold_y_train, batch_size=BATCH_SIZE, epochs=epochs, verbose=1,\n",
    "            callbacks = [ra_val])\n",
    "    gc.collect()\n",
    "    model.load_weights(\"../checkpoints/ft_fine_1b.h5\")\n",
    "    predict += model.predict([x_test,x_test_att,test_features], batch_size=BATCH_SIZE,verbose=1) / num_folds\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587449e-a9d1-4fff-8403-5ff903a68b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./predictions/ft_fine_1b.json\",\"w\") as f:\n",
    "    json.dump(predict.tolist(),f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf28c0-1067-4558-a5a1-63e042df8346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
