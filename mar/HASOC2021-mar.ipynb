{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HASOC2021-mar.ipynb","provenance":[{"file_id":"1fC0oLVLUvrB4y0vJGRr1TbFtHuN4Vnv7","timestamp":1628499428187}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e3468041a5f847c38bf9940acdf7ceb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d48cecb6048d4543a1b3fbbde085c878","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dfdc1271df2c42c18190b17259a0c61f","IPY_MODEL_7bb7fca016504296abe523b5881259bd","IPY_MODEL_80d9768526ec43fa92cf4738675ce1c1"]}},"d48cecb6048d4543a1b3fbbde085c878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfdc1271df2c42c18190b17259a0c61f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c8a54191955e467b8317b46ace385546","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cab4dba4a9e54817915555e7fa15999a"}},"7bb7fca016504296abe523b5881259bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9e1c6ccbe4344032a3a78d10acd5193d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":134982446,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":134982446,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d27fca766144429a8d0af2bdc17c073"}},"80d9768526ec43fa92cf4738675ce1c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3618145deb0542bb97bc29a8a94569fc","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 135M/135M [00:02&lt;00:00, 49.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f593501ba2054a2b96a44cf3f4932bc7"}},"c8a54191955e467b8317b46ace385546":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cab4dba4a9e54817915555e7fa15999a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e1c6ccbe4344032a3a78d10acd5193d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9d27fca766144429a8d0af2bdc17c073":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3618145deb0542bb97bc29a8a94569fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f593501ba2054a2b96a44cf3f4932bc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqcr8J1KnP0W","executionInfo":{"status":"ok","timestamp":1628499914176,"user_tz":-330,"elapsed":14956,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"7e679605-e743-45cd-c19d-e7589d88e2dd"},"source":["## Running for eng dataset\n","# loading basic things \n","\n","import os\n","from getpass import getpass\n","import urllib\n","\n","user = input('User name: ')\n","password = getpass('Password: ')\n","password = urllib.parse.quote(password) # your password is converted into url format\n","# repo_name = input('Repo name: ')\n","\n","cmd_string = 'git clone https://{0}:{1}@github.com/Adi2K/Precog-HASOC-2021.git'.format(user, password)\n","\n","# Can't authenticate by this method if you have 2 Factor Authentication enabled.\n","\n","os.system(cmd_string)\n","cmd_string, password = \"\", \"\" # removing the password from the variable\n","\n","%cd Precog-HASOC-2021/mar/data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["User name: Adi2K\n","Password: ··········\n","[Errno 2] No such file or directory: 'Precog-HASOC-2021'\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zifWu1QZK1Uq","executionInfo":{"status":"ok","timestamp":1628513388657,"user_tz":-330,"elapsed":38013,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"19296713-dc34-4381-811b-50973ae56ee2"},"source":["# Run these cells instead if you have 2 Factor Authentication enabled.\n","# After cloning the repo inside your Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7scKwIF1Ky-V","executionInfo":{"status":"ok","timestamp":1628513715581,"user_tz":-330,"elapsed":335,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Precog-HASOC-2021/mar/data\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"E-8yz259nu4u","executionInfo":{"status":"ok","timestamp":1628513716954,"user_tz":-330,"elapsed":7,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}}},"source":["import pandas as pd"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"0T09mE8ipWNs","executionInfo":{"status":"ok","timestamp":1628513719371,"user_tz":-330,"elapsed":340,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"ad8b121e-dbf5-43cc-c897-86fe9c4ca671"},"source":["df = pd.read_excel('mr_Hasoc2021_train.xlsx')\n","df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_id</th>\n","      <th>text</th>\n","      <th>task_1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hasoc_mr_1</td>\n","      <td>भारत 15 ऑगस्ट 1947 ला स्वतंत्र झाला आणि त्यानं...</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hasoc_mr_2</td>\n","      <td>स्वत ला हवा तसा बाइट किंवा प्रतिक्रिया घेण्यास...</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>hasoc_mr_3</td>\n","      <td>5 व्या नंबरची अर्थव्यवस्था आहे भारताची जगात 20...</td>\n","      <td>NOT</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>hasoc_mr_4</td>\n","      <td>च्यायला म्हणजे दुबईचा फोन ही पुडीच निघाली की.</td>\n","      <td>HOF</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>hasoc_mr_5</td>\n","      <td>ह्याला खरंतर कधीच आत टाकला पाहिजे होता. पैसा आ...</td>\n","      <td>HOF</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      text_id                                               text task_1\n","0  hasoc_mr_1  भारत 15 ऑगस्ट 1947 ला स्वतंत्र झाला आणि त्यानं...    NOT\n","1  hasoc_mr_2  स्वत ला हवा तसा बाइट किंवा प्रतिक्रिया घेण्यास...    NOT\n","2  hasoc_mr_3  5 व्या नंबरची अर्थव्यवस्था आहे भारताची जगात 20...    NOT\n","3  hasoc_mr_4      च्यायला म्हणजे दुबईचा फोन ही पुडीच निघाली की.    HOF\n","4  hasoc_mr_5  ह्याला खरंतर कधीच आत टाकला पाहिजे होता. पैसा आ...    HOF"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4mC2J8hqI24","executionInfo":{"status":"ok","timestamp":1628513720793,"user_tz":-330,"elapsed":8,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"9ea1cfef-a63d-49c3-9796-ce90e67a1bea"},"source":["df.info()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1874 entries, 0 to 1873\n","Data columns (total 3 columns):\n"," #   Column   Non-Null Count  Dtype \n","---  ------   --------------  ----- \n"," 0   text_id  1874 non-null   object\n"," 1   text     1874 non-null   object\n"," 2   task_1   1874 non-null   object\n","dtypes: object(3)\n","memory usage: 44.0+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NCQmYk8kvDGa","executionInfo":{"status":"ok","timestamp":1628513722069,"user_tz":-330,"elapsed":2,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}}},"source":["train=df.sample(frac=0.8,random_state=73)\n","test=df.drop(train.index)\n","train.to_csv('train_mar.csv')\n","test.to_csv('test_mar.csv')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"luwozZVHuiJ0","executionInfo":{"status":"ok","timestamp":1628513723949,"user_tz":-330,"elapsed":348,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}}},"source":["from collections import defaultdict as ddict \n","import csv\n","label_dict1 = {\n","    'NOT':0,\n","    'HOF':1\n","}\n","\n","def load_dataset(df=\"train_mar.csv\"):\n","  lines = []\n","  with open(df, \"r\") as f:\n","    reader = csv.reader(f)\n","    for line in reader:\n","      lines.append(line)\n","    tweet=[]\n","    label1 =[]\n","    dic_data = ddict(list)\n","    for (i,line) in enumerate(lines):\n","      if i==0:\n","        continue\n","\n","      _tweet = line[2]\n","      _label1 = line[3]\n","\n","      tweet.append(_tweet)\n","      label1.append(label_dict1[_label1])\n","    label_list1 = [\"HOF\", \"NOT\"]\n","    dic_data['tweet']=tweet\n","    dic_data['label1']=label1\n","    return dic_data,label_list1"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmaSzb6WwcSm","executionInfo":{"status":"ok","timestamp":1628513725305,"user_tz":-330,"elapsed":5,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"39b3f803-a87d-47f0-ee97-7865a303c7bf"},"source":["train_data, label_list1= load_dataset()\n","# print(train_data['hypothesis'][:10])\n","print(train_data['label1'][:5])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[1, 0, 1, 0, 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i2NV8x2_owml","executionInfo":{"status":"ok","timestamp":1628513737622,"user_tz":-330,"elapsed":10652,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"8749909c-b3f2-4264-ebcd-ecb91381d544"},"source":["import torch\n","!pip install transformers -q\n","!pip install tokenizers -q\n","!pip install datasets\n","from transformers import BertTokenizer, AutoTokenizer\n","from transformers import BertForSequenceClassification, AdamW, AutoModelForSequenceClassification"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n","Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.1)\n","Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MgiLnVj-qG0","executionInfo":{"status":"ok","timestamp":1628513742770,"user_tz":-330,"elapsed":2871,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"ecaf334b-5563-4e30-f56d-e4fc6609b1d8"},"source":["! pip install sentencepiece"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["e3468041a5f847c38bf9940acdf7ceb7","d48cecb6048d4543a1b3fbbde085c878","dfdc1271df2c42c18190b17259a0c61f","7bb7fca016504296abe523b5881259bd","80d9768526ec43fa92cf4738675ce1c1","c8a54191955e467b8317b46ace385546","cab4dba4a9e54817915555e7fa15999a","9e1c6ccbe4344032a3a78d10acd5193d","9d27fca766144429a8d0af2bdc17c073","3618145deb0542bb97bc29a8a94569fc","f593501ba2054a2b96a44cf3f4932bc7"]},"id":"qnrmjzWxqoqj","executionInfo":{"status":"ok","timestamp":1628513754118,"user_tz":-330,"elapsed":6446,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"d8bcddfe-1f3d-4822-9199-2e472efc3c90"},"source":["bert_tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')\n","model = AutoModelForSequenceClassification.from_pretrained('ai4bharat/indic-bert',num_labels=2)\n"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3468041a5f847c38bf9940acdf7ceb7","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/135M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Some weights of the model checkpoint at ai4bharat/indic-bert were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.weight', 'sop_classifier.classifier.bias', 'predictions.dense.bias', 'sop_classifier.classifier.weight', 'predictions.bias', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.decoder.bias', 'predictions.dense.weight']\n","- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF28lJenwWxa","executionInfo":{"status":"ok","timestamp":1628513763652,"user_tz":-330,"elapsed":343,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"0c8c3b14-2f7c-48f5-e626-30c6c3493167"},"source":["encoding = bert_tokenizer(train_data['tweet'] ,return_tensors='pt', padding=True)\n","print(encoding) "],"execution_count":11,"outputs":[{"output_type":"stream","text":["{'input_ids': tensor([[     2,  26294,   4384,  ...,      0,      0,      0],\n","        [     2, 100705,    494,  ...,      0,      0,      0],\n","        [     2,   8351,   6676,  ...,      0,      0,      0],\n","        ...,\n","        [     2,  69847,   7175,  ...,      0,      0,      0],\n","        [     2,   2092,   2863,  ...,      0,      0,      0],\n","        [     2,   5478,   1976,  ...,      0,      0,      0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zz_b6RpJxrll","executionInfo":{"status":"ok","timestamp":1628513830848,"user_tz":-330,"elapsed":340,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}}},"source":["class HASOC(torch.utils.data.Dataset):\n","  def __init__(self,encodings,labels):\n","    self.encodings=encodings\n","    self.labels = labels\n","  def __getitem__(self,idx):\n","    item ={key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","    item['labels'] = torch.tensor(self.labels[idx])\n","    return item\n","  def __len__(self):\n","        return len(self.labels)\n","\n","Data = HASOC(encoding,train_data['label1']) # binary right now, if 4 way classification change in BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=2)\n","\n","test_data, label_test_list1 = load_dataset('test_mar.csv')\n","test_encoding = bert_tokenizer(test_data['tweet'] ,return_tensors='pt', padding=True)\n","test_Data = HASOC(test_encoding,test_data['label1'])\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"csM_h7AMx-y5","executionInfo":{"status":"ok","timestamp":1628514360115,"user_tz":-330,"elapsed":255588,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}},"outputId":"376e2f78-70c9-4cbd-d714-b4865059b70d"},"source":["from transformers import Trainer,TrainingArguments\n","\n","import numpy as np\n","from datasets import load_metric\n","\n","metric = load_metric(\"accuracy\")\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)\n","\n","\n","training_args =TrainingArguments(\n","    output_dir ='./output',\n","    num_train_epochs=8,\n","    per_device_train_batch_size =8,\n","    warmup_steps=500,\n","    logging_dir ='./logs',\n","    logging_steps=20,\n","    evaluation_strategy=\"epoch\"\n","    \n",")\n","\n","trainer = Trainer(\n","    model =model,\n","    args = training_args,\n","    train_dataset = Data,\n","    eval_dataset =test_Data,\n","    compute_metrics=compute_metrics\n","\n","\n",")\n","trainer.train()\n","\n","# from torch.utils.data import DataLoader\n","# train_loader = DataLoader(Data, batch_size=16, shuffle=True)\n","\n","# optim = AdamW(model.parameters(), lr=5e-5)\n","\n","\n","# for epoch in range(5):\n","    \n","#     running_loss =0.0\n","#     for i,batch in enumerate(train_loader):\n","#         optim.zero_grad()\n","#         input_ids = batch['input_ids'].to(device)\n","#         attention_mask = batch['attention_mask'].to(device)\n","#         labels = batch['labels'].to(device)\n","#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","#         loss = outputs[0]\n","#         loss.backward()\n","#         optim.step()\n","#         running_loss += loss.item()\n","\n","#         if i % 20 == 19:    # print every 2000 mini-batches\n","#             print('[%d, %5d] loss: %.3f' %\n","#                   (epoch + 1, i + 1, running_loss / 2000))\n","#             running_loss = 0.0\n","\n","# model.eval()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","***** Running training *****\n","  Num examples = 1499\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1504\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1504' max='1504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1504/1504 04:14, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.636300</td>\n","      <td>0.553608</td>\n","      <td>0.746667</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.574100</td>\n","      <td>0.538853</td>\n","      <td>0.741333</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.574500</td>\n","      <td>0.543900</td>\n","      <td>0.752000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.469400</td>\n","      <td>0.542621</td>\n","      <td>0.757333</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.300900</td>\n","      <td>0.636447</td>\n","      <td>0.776000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.417500</td>\n","      <td>0.498491</td>\n","      <td>0.802667</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.346200</td>\n","      <td>0.476245</td>\n","      <td>0.840000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.257500</td>\n","      <td>0.472232</td>\n","      <td>0.834667</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","Saving model checkpoint to ./output/checkpoint-500\n","Configuration saved in ./output/checkpoint-500/config.json\n","Model weights saved in ./output/checkpoint-500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","Saving model checkpoint to ./output/checkpoint-1000\n","Configuration saved in ./output/checkpoint-1000/config.json\n","Model weights saved in ./output/checkpoint-1000/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","Saving model checkpoint to ./output/checkpoint-1500\n","Configuration saved in ./output/checkpoint-1500/config.json\n","Model weights saved in ./output/checkpoint-1500/pytorch_model.bin\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  \n","***** Running Evaluation *****\n","  Num examples = 375\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1504, training_loss=0.46964528403700667, metrics={'train_runtime': 254.9778, 'train_samples_per_second': 47.032, 'train_steps_per_second': 5.899, 'total_flos': 47018021581440.0, 'train_loss': 0.46964528403700667, 'epoch': 8.0})"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"ZI3R-JYz3vw7","executionInfo":{"status":"ok","timestamp":1628514449010,"user_tz":-330,"elapsed":332,"user":{"displayName":"ADITYA KADAM","photoUrl":"","userId":"13131346349791612764"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"seYx1JgryWJR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vm4SRVzE9R_D"},"source":[""],"execution_count":null,"outputs":[]}]}